"""
æ¼”ç¤ºå®Œæ•´çš„æ–‡æ¡£å¤„ç†æµç¨‹
è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„æ¼”ç¤ºè„šæœ¬ï¼Œå±•ç¤ºä»æ–‡ä»¶ä¸‹è½½åˆ°æ•°æ®ä¿å­˜çš„å®Œæ•´æµç¨‹
"""
import sys
import os
import time
import json
from typing import Dict, Any, List
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.core.database import db_manager
from src.services.file_operations import file_ops
from src.services.document_converter import doc_converter
from src.services.document_chunker import doc_chunker
from src.services.vectorizer import vectorizer
from src.utils.logger_config import app_logger

def demo_complete_flow():
    """æ¼”ç¤ºå®Œæ•´çš„æ–‡æ¡£å¤„ç†æµç¨‹"""
    
    print("ğŸš€ å¼€å§‹æ¼”ç¤ºå®Œæ•´çš„æ–‡æ¡£å¤„ç†æµç¨‹")
    print("=" * 60)
    
    # æ¨¡æ‹Ÿæ–‡ä»¶ä¿¡æ¯
    demo_files = [
        {
            'id': 'demo_file_001',
            'name': 'demo_document.pdf',
            'url': 'https://example.com/demo_document.pdf',
            'type': 'application/pdf',
            'size': 1024000
        },
        {
            'id': 'demo_file_002', 
            'name': 'demo_document.docx',
            'url': 'https://example.com/demo_document.docx',
            'type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            'size': 512000
        }
    ]
    
    processed_count = 0
    failed_count = 0
    
    for i, file_info in enumerate(demo_files, 1):
        file_id = file_info['id']
        file_name = file_info['name']
        
        print(f"\nğŸ“„ å¤„ç†æ–‡ä»¶ {i}/{len(demo_files)}: {file_name}")
        print("-" * 40)
        
        try:
            # æ­¥éª¤1: æ·»åŠ æ–‡ä»¶åˆ°æ•°æ®åº“
            print("  ğŸ“ æ­¥éª¤1: æ·»åŠ æ–‡ä»¶åˆ°å¤„ç†é˜Ÿåˆ—")
            db_manager.add_file(
                file_id=file_id,
                file_name=file_name,
                file_url=file_info['url'],
                file_size=file_info['size'],
                file_type=file_info['type'],
                metadata=file_info
            )
            print(f"     âœ… æ–‡ä»¶å·²æ·»åŠ åˆ°é˜Ÿåˆ—: {file_name}")
            
            # æ­¥éª¤2: æ¨¡æ‹Ÿä¸‹è½½æ–‡ä»¶
            print("  ğŸ“¥ æ­¥éª¤2: ä¸‹è½½æ–‡ä»¶")
            db_manager.update_status(file_id, "downloading")
            time.sleep(1)  # æ¨¡æ‹Ÿä¸‹è½½æ—¶é—´
            
            # æ¨¡æ‹Ÿä¸‹è½½è·¯å¾„
            download_path = f"/tmp/downloads/{file_id}_{file_name}"
            db_manager.update_status(file_id, "downloaded", download_path=download_path)
            print(f"     âœ… æ–‡ä»¶ä¸‹è½½å®Œæˆ: {download_path}")
            
            # æ­¥éª¤3: æ¨¡æ‹Ÿè½¬æ¢æ–‡æ¡£
            print("  ğŸ”„ æ­¥éª¤3: è½¬æ¢æ–‡æ¡£ä¸ºMarkdown")
            db_manager.update_status(file_id, "converting")
            time.sleep(2)  # æ¨¡æ‹Ÿè½¬æ¢æ—¶é—´
            
            # æ¨¡æ‹Ÿè½¬æ¢åçš„Markdownè·¯å¾„
            markdown_path = f"/tmp/output/markdown/{file_id}.md"
            db_manager.update_status(file_id, "converted", markdown_path=markdown_path)
            print(f"     âœ… æ–‡æ¡£è½¬æ¢å®Œæˆ: {markdown_path}")
            
            # æ­¥éª¤4: æ¨¡æ‹Ÿåˆ‡ç‰‡æ–‡æ¡£
            print("  âœ‚ï¸  æ­¥éª¤4: åˆ‡ç‰‡æ–‡æ¡£")
            db_manager.update_status(file_id, "chunking")
            time.sleep(1)  # æ¨¡æ‹Ÿåˆ‡ç‰‡æ—¶é—´
            
            # æ¨¡æ‹Ÿåˆ‡ç‰‡ç»“æœ
            chunk_count = 5  # å‡è®¾ç”Ÿæˆ5ä¸ªåˆ‡ç‰‡
            chunks = [
                {
                    'id': f"{file_id}_chunk_{j}",
                    'content': f"è¿™æ˜¯ç¬¬{j}ä¸ªåˆ‡ç‰‡çš„å†…å®¹...",
                    'metadata': {'chunk_index': j, 'file_id': file_id}
                }
                for j in range(1, chunk_count + 1)
            ]
            db_manager.update_status(file_id, "chunked", chunk_count=chunk_count)
            print(f"     âœ… æ–‡æ¡£åˆ‡ç‰‡å®Œæˆ: ç”Ÿæˆäº† {chunk_count} ä¸ªåˆ‡ç‰‡")
            
            # æ­¥éª¤5: æ¨¡æ‹Ÿå‘é‡åŒ–åˆ‡ç‰‡
            print("  ğŸ§  æ­¥éª¤5: å‘é‡åŒ–åˆ‡ç‰‡")
            db_manager.update_status(file_id, "vectorizing")
            time.sleep(3)  # æ¨¡æ‹Ÿå‘é‡åŒ–æ—¶é—´
            
            # æ¨¡æ‹Ÿå‘é‡åŒ–ç»“æœ
            vectorized_chunks = [
                {
                    'chunk_id': chunk['id'],
                    'content': chunk['content'],
                    'embedding': [0.1, 0.2, 0.3, 0.4, 0.5],  # æ¨¡æ‹Ÿå‘é‡
                    'metadata': chunk['metadata']
                }
                for chunk in chunks
            ]
            db_manager.update_status(file_id, "vectorized", vector_count=len(vectorized_chunks))
            print(f"     âœ… åˆ‡ç‰‡å‘é‡åŒ–å®Œæˆ: ç”Ÿæˆäº† {len(vectorized_chunks)} ä¸ªå‘é‡")
            
            # æ­¥éª¤6: æ¨¡æ‹Ÿä¿å­˜æ•°æ®
            print("  ğŸ’¾ æ­¥éª¤6: ä¿å­˜æ•°æ®åˆ°å‘é‡æ•°æ®åº“")
            db_manager.update_status(file_id, "saving")
            time.sleep(1)  # æ¨¡æ‹Ÿä¿å­˜æ—¶é—´
            
            # æ¨¡æ‹Ÿä¿å­˜æˆåŠŸ
            db_manager.update_status(file_id, "completed")
            print(f"     âœ… æ•°æ®ä¿å­˜å®Œæˆ")
            
            processed_count += 1
            print(f"  ğŸ‰ æ–‡ä»¶å¤„ç†å®Œæˆ: {file_name}")
            
        except Exception as e:
            print(f"  âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {file_name} - {str(e)}")
            db_manager.update_status(file_id, "failed", error_message=str(e))
            failed_count += 1
    
    # ç”Ÿæˆå¤„ç†æŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“Š å¤„ç†æŠ¥å‘Š")
    print("=" * 60)
    print(f"æ€»æ–‡ä»¶æ•°: {len(demo_files)}")
    print(f"æˆåŠŸå¤„ç†: {processed_count}")
    print(f"å¤„ç†å¤±è´¥: {failed_count}")
    print(f"æˆåŠŸç‡: {processed_count / len(demo_files) * 100:.1f}%")
    
    # æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡
    try:
        stats = db_manager.get_statistics()
        print(f"\nğŸ“ˆ æ•°æ®åº“ç»Ÿè®¡:")
        print(f"  æ€»æ–‡ä»¶æ•°: {stats.get('total_files', 0)}")
        print(f"  å¾…å¤„ç†: {stats.get('pending_files', 0)}")
        print(f"  å¤„ç†ä¸­: {stats.get('processing_files', 0)}")
        print(f"  å·²å®Œæˆ: {stats.get('completed_files', 0)}")
        print(f"  å¤±è´¥: {stats.get('failed_files', 0)}")
    except Exception as e:
        print(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")
    
    print("\nğŸ¯ æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 60)

def show_processing_status():
    """æ˜¾ç¤ºå½“å‰å¤„ç†çŠ¶æ€"""
    try:
        stats = db_manager.get_statistics()
        print("ğŸ“Š å½“å‰å¤„ç†çŠ¶æ€:")
        print(json.dumps(stats, indent=2, ensure_ascii=False))
        
        # æ˜¾ç¤ºå„çŠ¶æ€çš„æ–‡ä»¶åˆ—è¡¨
        from src.core.database import FileProcessingStatus
        
        print("\nğŸ“‹ æ–‡ä»¶çŠ¶æ€è¯¦æƒ…:")
        all_files = db_manager.session.query(FileProcessingStatus).all()
        for file_status in all_files:
            print(f"  {file_status.file_name} ({file_status.file_id}): {file_status.status}")
            
    except Exception as e:
        print(f"è·å–çŠ¶æ€å¤±è´¥: {str(e)}")

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) > 1 and sys.argv[1] == '--status':
        show_processing_status()
    else:
        demo_complete_flow()
    
    # å…³é—­æ•°æ®åº“è¿æ¥
    db_manager.close()

if __name__ == '__main__':
    main()
